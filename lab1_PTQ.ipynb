{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 本次实验包括后量化的过程，主要在于学习如何对DNN的权重（weight）和激活层（activation）进行量化。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 引用外部软件包\n",
    "import torch # pytorch包\n",
    "import torchvision # torchvision是pytorch官方提供的工具，包含很多常用数据集的封装等\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn # nn 和下面的F均包含了主要的神经网络模块，包括卷积层、全连接层、池化层等等\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim # 优化器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 确保device为gpu，否则会花费过长时间。\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.cuda.set_device(0) # 服务器上一共有两块显卡，可以自行设定使用第一块还是第二块（0 or 1）。在命令行端口输入nvidia-smi命令可以查看当前显卡的占用情况。\n",
    "    # device = torch.device('cuda')\n",
    "    print('using cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('using cpu')\n",
    "\n",
    "# 设置量化位宽\n",
    "bitwidth_A = 8\n",
    "bitwidth_W = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training and test data from the CIFAR10 dataset.\n",
    "# torchvision是pytorch官方集成的工具库，包括学界常用的数据集和数据预处理方式。\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(), # 将数据归一化，并转换成tensor的形式\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) # 预处理数据的方式，normalize是将图像进行规则化。\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='/your/path/to/download/dataset', train=True,\n",
    "                                        download=True, transform=transform) #定义了训练集，path是训练数据所在地址，指定位置自动下载。\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2) #定义数据迭代器，batchsize为一次迭代训练，送进去图像的数量（可以尝试调整，看看会发生什么）。shuffle表示要不要打乱训练图像的排序。\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='/your/path/to/download/dataset', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple CNN that classifies CIFAR images.\n",
    "# The network provided is similar to LeNet-5, and it has the following architecture:\n",
    "\n",
    "# **Layer** |     **Type**    | **Input Shape** | **Output Shape** | **Activation**\n",
    "#   conv1   |  Convolutional  |     3x32x32     |     6x28x28      |      ReLU \n",
    "#   pool1   |     Max pool    |     6x28x28     |     6x14x14      |      None                \n",
    "#   conv2   |  Convolutional  |     6x14x14     |     16x10x10     |      ReLU                \n",
    "#   pool2   |     Max pool    |     16x10x10    |     16x5x5       |      None                \n",
    "#   fc1     | Fully-connected |       400       |       120        |      ReLU                \n",
    "#   fc2     | Fully-connected |       120       |       84         |      ReLU                \n",
    "#   fc3     | Fully-connected |       84        |       10         |      None                \n",
    "\n",
    "# None of the layers in the network have a bias associated with them.\n",
    "# This makes them easier to quantize.\n",
    "# Towards the end of this assignment, we will add biases to the final layer and quantize it as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络定义，conv2d是卷积层，linear是全连接层。forward下定义了计算图，显示送进来的图像（x）会怎么处理。\n",
    "class Net(nn.Module):\n",
    "    #网络结构:2层卷积层、1层最大值池化层、3层全连接层，留意这些参数的内涵\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5, bias=False)\n",
    "        self.pool = nn.MaxPool2d(2, 2) # run after each conv (hence the 5x5 FC layer)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, bias=False)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120, bias=False)\n",
    "        self.fc2 = nn.Linear(120, 84, bias=False)\n",
    "        self.fc3 = nn.Linear(84, 10, bias=False)\n",
    "    #定义前向传播,将tensor数据送入网络之后的计算图\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net().to(device)\n",
    "# 到这里，我们定义好了网络和数据集的使用方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "#将训练集的dataloader送入网络进行训练,每次读取batchsize数量的数据\n",
    "def train(model: nn.Module, dataloader: DataLoader):\n",
    "    criterion = nn.CrossEntropyLoss() # loss function（交叉熵损失函数）\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9) #optimizer，使用SGD优化器训练，第一个参数表示model的所有参数都会参与训练，学习率为0.001，动量为0.9\n",
    "\n",
    "    for epoch in range(2):  # loop over the dataset multiple times。epoch指遍历所有训练集图像的次数。这里遍历所有训练图像两次\n",
    "\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(dataloader, 0): # dataloader是数据迭代器，从这里每次读出batchsize数量的数据。\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs) # 将数据送进网络，得到结果\n",
    "            loss = criterion(outputs, labels) # 计算结果和标签的交叉熵损失函数\n",
    "            loss.backward() # 基于上述损失函数求解梯度\n",
    "            optimizer.step() # 更新参数\n",
    "\n",
    "            # print statistics\n",
    "            running_loss += loss.item() # 将loss的值取出来，记录其变化\n",
    "            if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "                print('[%d, %5d] loss: %.3f' %\n",
    "                    (epoch + 1, i + 1, running_loss / 2000))\n",
    "                running_loss = 0.0\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "def test(model: nn.Module, dataloader: DataLoader, max_samples=None) -> float:\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    n_inferences = 0\n",
    "\n",
    "    with torch.no_grad(): # 测试时不用求解梯度，因此可以设置不计算梯度的模式\n",
    "        for data in dataloader:\n",
    "            images, labels = data\n",
    "\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images) # get 1 batch worth of image predictions (i.e. 4 predictions of 10 each)\n",
    "            other, predicted = torch.max(outputs.data, 1) # other == values, predicted == indicies\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "            if max_samples:\n",
    "                n_inferences += images.shape[0]\n",
    "                if n_inferences > max_samples:\n",
    "                    break\n",
    "    \n",
    "    return 100 * correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(net, trainloader) # 进行训练，将网络定义和数据迭代器传给train函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that the CNN has been trained, let's test it on our test dataset.\n",
    "score = test(net, testloader)\n",
    "print('Accuracy of the network on the test images: {}%'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a convenience function which we use to copy CNN's.\n",
    "from copy import deepcopy\n",
    "\n",
    "def copy_model(model: nn.Module) -> nn.Module:\n",
    "    result = deepcopy(model)\n",
    "\n",
    "    # Copy over the extra metadata we've collected which copy.deepcopy doesn't capture\n",
    "    if hasattr(model, 'input_activations'):\n",
    "        result.input_activations = deepcopy(model.input_activations)\n",
    "\n",
    "    for result_layer, original_layer in zip(result.children(), model.children()):\n",
    "        if isinstance(result_layer, nn.Conv2d) or isinstance(result_layer, nn.Linear):\n",
    "            if hasattr(original_layer.weight, 'scale'):\n",
    "                result_layer.weight.scale = deepcopy(original_layer.weight.scale)\n",
    "            if hasattr(original_layer, 'activations'):\n",
    "                result_layer.activations = deepcopy(original_layer.activations)\n",
    "            if hasattr(original_layer, 'output_scale'):\n",
    "                result_layer.output_scale = deepcopy(original_layer.output_scale)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 1: Visualize Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question 1.1:\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "name = ['conv1', 'conv2', 'fc1', 'fc2', 'fc3']\n",
    "n = 0\n",
    "\n",
    "for layer in net.children(): # 遍历类的成员\n",
    "    if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "        weight = layer.weight.data.cpu().view(-1).numpy()\n",
    "        print(name[n] + \": the range is [{:.5f}, {:.5f}]\".format(weight.min(), weight.max()))\n",
    "\n",
    "        # find 3-sigma range (u-3s, u+3s), 该范围能囊括99.73%参数\n",
    "        sigma3 = int(np.size(weight)*0.0027) \n",
    "        sigma3_value = np.abs(weight)[np.argpartition(np.abs(weight), -sigma3)[-sigma3]]\n",
    "        print(name[n] + \": the 3-sigma range is [{:.5f}, {:.5f}]\".format(max(-sigma3_value, weight.min()), min(sigma3_value,weight.max())))\n",
    "\n",
    "        plt.hist(weight, bins=50, facecolor=\"blue\", edgecolor=\"black\", alpha=0.7) # 画直方图\n",
    "        plt.xlabel(\"range\")\n",
    "        plt.ylabel(\"frequency\")\n",
    "        plt.title(name[n])\n",
    "        plt.show()\n",
    "        n += 1\n",
    "        \n",
    "# You can get a flattened vector of the weights of fc1 like this:\n",
    "#   fc1_weights = net.fc1.weight.data.cpu().view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question 1.2: Explain which range you would prefer to use if you were to quantize each layer's weights and wanted to strike a balance between the range of values that could be expressed, and your precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 2: Quantize Weights 首先我们把原来网络的参数copy到net_q2。\n",
    "\n",
    "net_q2 = copy_model(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question 2.1:\n",
    "\n",
    "from typing import Tuple\n",
    "# 确定scale进行量化\n",
    "def quantized_weights(weights: torch.Tensor, bitwidth_W: int):\n",
    "    '''\n",
    "    Quantize the weights so that all values are integers between -128 and 127.\n",
    "    You may want to use the total range, 3-sigma range, or some other range when\n",
    "    deciding just what factors to scale the float32 values by.\n",
    "\n",
    "    Parameters:\n",
    "    weights (Tensor): The unquantized weights\n",
    "    #输入数据是尚未量化过的权重\n",
    "\n",
    "    Returns:\n",
    "    #返回数据是一个元组,(quantization result , scale )\n",
    "    (Tensor, float): A tuple with the following elements:\n",
    "                        * The weights in quantized form, where every value is an integer between -128 and 127.\n",
    "                          The \"dtype\" will still be \"float\", but the values themselves should all be integers.\n",
    "                        * The scaling factor that your weights were multiplied by.\n",
    "                          This value does not need to be an 8-bit integer.\n",
    "    '''\n",
    "\n",
    "    # modify the following code to try other range\n",
    "\n",
    "    W_border = 2**(bitwidth_W-1)\n",
    "    w = weights.data.cpu().view(-1).numpy() # 这里将tensor转入numpy只是为了之后的计算\n",
    "    sigma3 = int(np.size(w)*0.0027)\n",
    "    sigma3_value = np.abs(w)[np.argpartition(np.abs(w), -sigma3)[-sigma3]] \n",
    "    weights = weights/sigma3_value*W_border\n",
    "    quan_weight = weights.round() # 转化为值最接近的整数\n",
    "\n",
    "    return torch.clamp(quan_weight, min=-W_border, max=W_border-1), W_border/sigma3_value # clamp是切顶函数。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantize_layer_weights(model: nn.Module, bitwidth_W: int):\n",
    "    for layer in model.children():\n",
    "        if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "            q_layer_data, scale = quantized_weights(layer.weight.data, bitwidth_W)\n",
    "            q_layer_data = q_layer_data.to(device)\n",
    "\n",
    "            layer.weight.data = q_layer_data\n",
    "            layer.weight.scale = scale\n",
    "            print(scale)\n",
    "\n",
    "            if (q_layer_data < -2**(bitwidth_W-1)).any() or (q_layer_data > (2**(bitwidth_W-1)-1)).any():\n",
    "                raise Exception(\"Quantized weights of {} layer include values out of bounds for an 8-bit signed integer\".format(layer.__class__.__name__))\n",
    "            if (q_layer_data != q_layer_data.round()).any():\n",
    "                raise Exception(\"Quantized weights of {} layer include non-integer values\".format(layer.__class__.__name__))\n",
    "\n",
    "quantize_layer_weights(net_q2, bitwidth_W)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question 2.2:\n",
    "\n",
    "#Record the accuracy change of the network after quantizing its weights. If you’ve done everything correctly, the accuracy change should be negligible.\n",
    "\n",
    "score = test(net_q2, testloader)\n",
    "print('Accuracy of the network after quantizing all weights: {}%'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 3: Visualize Activations\n",
    "\n",
    "# Now that we have quantized the weights of the CNN, we must also quantize the activations (inputs and outputs to layers) traveling through it.\n",
    "# But before doing so, let's analyze what values the activations take when travelling through the network.\n",
    "\n",
    "# We provide convenience code which will record the values of every pixel of the outputs and inputs travelling through the neural network.\n",
    "# (This is the initial CNN, where not even the weights had yet been quantized).\n",
    "# We then profile these values when running on a subset of the training set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hook，顾名思义，其作用是把网络推理时的中间变量勾出来。通过hook函数，我们可以统计中间变量的范围。\n",
    "\"\"\"\n",
    "pytorch中的hook机制:\n",
    "Pytorch会自动舍弃图计算中间结果,用hook以获取某些变量的中间结果.要及时删除,避免增加运行负载\n",
    "\n",
    "Tensor级别：\n",
    "register_hook(hook)->Tensor:为Tensor注册一个backward hook 获取变量梯度\n",
    "hook遵循格式:hook(grad)->Tensor\n",
    "nn.Module对象级别:\n",
    "register_forward_hook(hook)\n",
    "此时hook可以修改input和output却不影响forward结果,典型场景是提取中间层的输出特征,又不希望修改原有模型定义文件\n",
    "格式为hook(layer,input,output)\n",
    "\"\"\"\n",
    "def register_activation_profiling_hooks(model: Net):\n",
    "    model.input_activations = np.empty(0)\n",
    "    model.conv1.activations = np.empty(0)\n",
    "    model.conv2.activations = np.empty(0)\n",
    "    model.fc1.activations = np.empty(0)\n",
    "    model.fc2.activations = np.empty(0)\n",
    "    model.fc3.activations = np.empty(0)\n",
    "    \n",
    "    model.profile_activations = True\n",
    "\n",
    "    def conv1_activations_hook(layer, x, y):\n",
    "        if model.profile_activations:\n",
    "            model.input_activations = np.append(model.input_activations, x[0].cpu().view(-1))\n",
    "    model.conv1.register_forward_hook(conv1_activations_hook)#寄存器暂时存下传递到下一层的activatio,下同\n",
    "\n",
    "    def conv2_activations_hook(layer, x, y):\n",
    "        if model.profile_activations:\n",
    "            model.conv1.activations = np.append(model.conv1.activations, x[0].cpu().view(-1))\n",
    "    model.conv2.register_forward_hook(conv2_activations_hook)\n",
    "\n",
    "    def fc1_activations_hook(layer, x, y):\n",
    "        if model.profile_activations:\n",
    "            model.conv2.activations = np.append(model.conv2.activations, x[0].cpu().view(-1))\n",
    "    model.fc1.register_forward_hook(fc1_activations_hook)\n",
    "    \n",
    "\n",
    "    def fc2_activations_hook(layer, x, y):\n",
    "        if model.profile_activations:\n",
    "            model.fc1.activations = np.append(model.fc1.activations, x[0].cpu().view(-1))\n",
    "    model.fc2.register_forward_hook(fc2_activations_hook)\n",
    "\n",
    "    def fc3_activations_hook(layer, x, y):\n",
    "        if model.profile_activations:\n",
    "            model.fc2.activations = np.append(model.fc2.activations, x[0].cpu().view(-1))\n",
    "            model.fc3.activations = np.append(model.fc3.activations, y[0].cpu().view(-1))\n",
    "    model.fc3.register_forward_hook(fc3_activations_hook)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the unquantized model to profile input and output activations on a subset of the training dataset.\n",
    "\n",
    "net_q3 = copy_model(net)\n",
    "register_activation_profiling_hooks(net_q3)#把各个中间层都记录下来\n",
    "\n",
    "# Run through the training dataset again while profiling the input and output activations this time\n",
    "# We don't actually have to perform gradient descent for this, so we can use the \"test\" function\n",
    "test(net_q3, trainloader, max_samples=400) # 跑400次，统计中间变量的数值范围\n",
    "net_q3.profile_activations = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question 3.1:\n",
    "\n",
    "# Plot histograms of the input images and the outputs of every convolutional and fully-connected layer. \n",
    "# Record any observations you make about the distribution of the values.\n",
    "# ADD YOUR CODE HERE \n",
    "Activation_border = 2**(bitwidth_A-1)\n",
    "input_activations = net_q3.input_activations # 输入数据\n",
    "conv1_output_activations = net_q3.conv1.activations # 第一层卷积层的输出数据\n",
    "conv2_output_activations = net_q3.conv2.activations # 第二层卷积层的输出数据\n",
    "fc1_output_activations = net_q3.fc1.activations # 同上类推\n",
    "fc2_output_activations = net_q3.fc2.activations\n",
    "fc3_output_activations = net_q3.fc3.activations\n",
    "\n",
    "# to plot distributions of activations\n",
    "# Plot histograms of the following variables, and calculate their ranges and 3-sigma ranges:\n",
    "\n",
    "#   input_activations\n",
    "\n",
    "#   conv1_output_activations\n",
    "\n",
    "#   conv2_output_activations\n",
    "\n",
    "#   fc1_output_activations\n",
    "\n",
    "#   fc2_output_activations\n",
    "\n",
    "#   fc3_output_activations\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question 3.2:\n",
    "\n",
    "# Additionally, record the range of the values, as well as their 3-sigma range (the difference between $\\mu + 3\\sigma$ and $\\mu - 3\\sigma$).\n",
    "# For which layers is the 3-sigma range larger or smaller than the actual range?\n",
    "# Then explain which range you would prefer to use if you were to quantize each layer's weights and wanted to strike a balance between the range of values that could be expressed, and your precision.\n",
    "# Remember that you are plotting the activations *after* activation functions like ReLU have been applied, which means that you should not be worried if you find that your plots are asymmetric.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 4: Quantize Activations\n",
    "\n",
    "# Complete the `quantize_initial_input` and `quantize_activations` functions which calculate the scaling factors for the initial image which is input to the CNN, and the outputs of each layer, respectively.\n",
    "\n",
    "# complete the `forward` function for the `NetQuantized` class.\n",
    "# You will have to add code here to scale the outputs of each layer, and then to clamp the outputs of each layer to integers between -128 and 127 afterwards.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "class NetQuantized(nn.Module):\n",
    "    def __init__(self, net_with_weights_quantized: nn.Module, bitwidth_A: int):\n",
    "        super(NetQuantized, self).__init__()\n",
    "        \n",
    "        net_init = copy_model(net_with_weights_quantized) # 最初的网络copy 过来,用于初始化量化网络\n",
    "\n",
    "        self.conv1 = net_init.conv1\n",
    "        self.pool = net_init.pool\n",
    "        self.conv2 = net_init.conv2\n",
    "        self.fc1 = net_init.fc1\n",
    "        self.fc2 = net_init.fc2\n",
    "        self.fc3 = net_init.fc3\n",
    "        self.activation_border = 2**(bitwidth_A-1)\n",
    "        print(self.activation_border)\n",
    "\n",
    "        for layer in self.conv1, self.conv2, self.fc1, self.fc2, self.fc3:\n",
    "            #逐层遍历,检查量化是否成功\n",
    "            def pre_hook(l, x):\n",
    "                x = x[0]\n",
    "                #异常处理:检查之前的量化是否将所有的数转化进规定的区间\n",
    "                if (x < -self.activation_border).any() or (x > (self.activation_border-1)).any():\n",
    "                    raise Exception(\"Input to {} layer is out of bounds for an {}-bit signed integer\".format(l.__class__.__name__, bitwidth_A))\n",
    "                if (x != x.round()).any():\n",
    "                    raise Exception(\"Input to {} layer has non-integer values\".format(l.__class__.__name__))\n",
    "\n",
    "            layer.register_forward_pre_hook(pre_hook)\n",
    "\n",
    "        # Calculate the scaling factor for the initial input to the CNN\n",
    "        self.input_activations = net_with_weights_quantized.input_activations\n",
    "        self.input_scale = NetQuantized.quantize_initial_input(self.input_activations, self.activation_border)\n",
    "        #以上2行计算了input activation 的scale和对应的quantization 版本\n",
    "        # Calculate the output scaling factors for all the layers of the CNN\n",
    "\n",
    "        for layer in self.conv1, self.conv2, self.fc1, self.fc2, self.fc3:\n",
    "            # layer.output_scale = NetQuantized.quantize_activations(...)\n",
    "            pass # call quantize_activations and add your code here\n",
    "\n",
    "    #计算输入的scale函数\n",
    "    @staticmethod\n",
    "    def quantize_initial_input(pixels: np.ndarray, activation_border:int):\n",
    "        '''\n",
    "        Calculate a scaling factor for the images that are input to the first layer of the CNN.\n",
    "\n",
    "        Parameters:\n",
    "        pixels (ndarray): The values of all the pixels which were part of the input image during training\n",
    "\n",
    "        Returns:\n",
    "        float: A scaling factor that the input should be multiplied by before being fed into the first layer.\n",
    "               This value does not need to be an 8-bit integer.\n",
    "        '''\n",
    "\n",
    "        sigma3 = int(np.size(pixels)*0.0027)\n",
    "        sigma3_value = pixels[np.argpartition(pixels,-sigma3)[-sigma3]]\n",
    "        max_value = np.max(np.abs(pixels))\n",
    "        scale = activation_border/sigma3_value  # you can modify the range here\n",
    "        return scale\n",
    "\n",
    "    # 逐层激活送入量化\n",
    "    @staticmethod\n",
    "    def quantize_activations( n_w: float, pre_activation_scale: float, now_activation_scale: float) -> float:\n",
    "        '''\n",
    "        Calculate a scaling factor to multiply the output of a layer by.\n",
    "\n",
    "        Parameters:\n",
    "        activations (ndarray): The values of all the pixels which have been output by this layer during training\n",
    "        n_w (float): The scale by which the weights of this layer were multiplied as part of the \"quantize_weights\" function you wrote earlier\n",
    "        n_initial_input (float): The scale by which the initial input to the neural network was multiplied\n",
    "        ns ([(float, float)]): A list of tuples, where each tuple represents the \"weight scale\" and \"output scale\" (in that order) for every preceding layer\n",
    "        #用一个元组记录已经算好的所有网络的weight scale 和 output scale\n",
    "        Returns:\n",
    "        float: A scaling factor that the layer output should be multiplied by before being fed into the first layer.\n",
    "               This value does not need to be an 8-bit integer.\n",
    "        '''\n",
    "\n",
    "        # ADD YOUR CODE HERE\n",
    "        scale = 0\n",
    "        return scale\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        # You can access the output activation scales like this:\n",
    "        #   fc1_output_scale = self.fc1.output_scale\n",
    "\n",
    "        # 这里其实是对定点数计算的模拟仿真，因此每层的输出均需要手动乘以scaling factor，并限制在规定的表示范围内。\n",
    "        # output_scale:不同网络层之间传递整数重新压缩为8bit的scale(在第三周阅读论文中是定点浮点数M)\n",
    "        # activation_scale:网络层内数据和真实值差距的scale\n",
    "        # weight_scale:权重量化值和真实值差距的scale\n",
    "        x = x*self.input_scale \n",
    "        x = torch.clamp(x.round(), min=-self.activation_border, max=self.activation_border-1) # 8bit是-128~127\n",
    "\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = x*self.conv1.output_scale\n",
    "        x = torch.clamp(x.round(), min=-self.activation_border, max=self.activation_border-1)\n",
    "\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x*self.conv2.output_scale\n",
    "        x = torch.clamp(x.round(), min=-self.activation_border, max=self.activation_border-1)     \n",
    "\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))   \n",
    "        x = x*self.fc1.output_scale\n",
    "        x = torch.clamp(x.round(), min=-self.activation_border, max=self.activation_border-1)  \n",
    "\n",
    "\n",
    "        x = F.relu(self.fc2(x))   \n",
    "        x = x*self.fc2.output_scale\n",
    "        x = torch.clamp(x.round(), min=-self.activation_border, max=self.activation_border-1) \n",
    "\n",
    "\n",
    "        x = self.fc3(x)*self.fc3.output_scale\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the information from net_q2 and net_q3 together\n",
    "#weight quantization & activation quantization \n",
    "net_init = copy_model(net_q2)\n",
    "net_init.input_activations = deepcopy(net_q3.input_activations)\n",
    "for layer_init, layer_q3 in zip(net_init.children(), net_q3.children()):\n",
    "    if isinstance(layer_init, nn.Conv2d) or isinstance(layer_init, nn.Linear):\n",
    "        layer_init.activations = deepcopy(layer_q3.activations)\n",
    "\n",
    "net_quantized = NetQuantized(net_init, bitwidth_A)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, record the accuracy of your network after both weights and activations have been quantized.\n",
    "# If you've done everything right, you should still find almost no accuracy change.\n",
    "\n",
    "score = test(net_quantized, testloader)\n",
    "print('Accuracy of the network after quantizing both weights and activations: {}%'.format(score))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Question 5: Quantize Biases 以下为选做内容\n",
    "\n",
    "# Let us now update our CNN to include a bias in its final layer, *fc3*.\n",
    "# We have already included code to create and train a new CNN called `net_with_bias`.\n",
    "\n",
    "# Consider how a bias affects the equation for an unquantized layer:\n",
    "\n",
    "# W * In + bias = Out\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question 5.1:\n",
    "\n",
    "# Suppose that we again quantized a biased layer with the same scaling factors we used in previous questions: $n_W$, $n_{In}$, and $n_{Out}$.\n",
    "# What would we scale bias by in this case?\n",
    "# Write an equation in your lab report to describe the output of the quantized layer with a bias.\n",
    "\n",
    "# Create a new network with a bias on *fc3*.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetWithBias(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NetWithBias, self).__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5, bias=False)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5, bias=False)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120, bias=False)\n",
    "        self.fc2 = nn.Linear(120, 84, bias=False)\n",
    "        self.fc3 = nn.Linear(84, 10, bias=True) # 最后一层的网络产生bias,这就是和之前的区别\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net_with_bias = NetWithBias().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train(net_with_bias, trainloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = test(net_with_bias, testloader)\n",
    "print('Accuracy of the network (with a bias) on the test images: {}%'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "register_activation_profiling_hooks(net_with_bias)\n",
    "test(net_with_bias, trainloader, max_samples=400)\n",
    "net_with_bias.profile_activations = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_with_bias_with_quantized_weights = copy_model(net_with_bias)\n",
    "quantize_layer_weights(net_with_bias_with_quantized_weights)\n",
    "\n",
    "score = test(net_with_bias_with_quantized_weights, testloader)\n",
    "print('Accuracy of the network on the test images after all the weights are quantized but the bias isn\\'t: {}%'.format(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill in the `quantized_bias` function in the `NetQuantizedWithBias` class.\n",
    "# This function is meant to quantize the bias on the final layer of the CNN.\n",
    "# Keep in mind that biases are typically quantized to 32-bits, so your bias values do not all have to be between -128 and 127 (though 32-bits is a bit conservative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slightly clearer bias bounds (32b signed integer)\n",
    "#bias量化后的最大值、最小值\n",
    "MIN_32B_SINT = -(2**31) \n",
    "MAX_32B_SINT = (2**31) - 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NetQuantizedWithBias(NetQuantized):\n",
    "    def __init__(self, net_with_weights_quantized: nn.Module):\n",
    "        super(NetQuantizedWithBias, self).__init__(net_with_weights_quantized)\n",
    "\n",
    "        preceding_scales = [(layer.weight.scale, layer.output_scale) for layer in self.children() if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear)][:-1]\n",
    "\n",
    "        self.fc3.bias.data = NetQuantizedWithBias.quantized_bias(\n",
    "            self.fc3.bias.data,\n",
    "            self.fc3.weight.scale,\n",
    "            self.input_scale,\n",
    "            preceding_scales\n",
    "        )\n",
    "        \n",
    "        self.quantized_bias()\n",
    "\n",
    "\n",
    "        if (self.fc3.bias.data < MIN_32B_SINT).any() or (self.fc3.bias.data > MAX_32B_SINT).any():\n",
    "            raise Exception(\"Bias has values which are out of bounds for an 32-bit signed integer\")\n",
    "        if (self.fc3.bias.data != self.fc3.bias.data.round()).any():\n",
    "            raise Exception(\"Bias has non-integer values\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def quantized_bias(bias: torch.Tensor, n_w: float, n_initial_input: float, ns: List[Tuple[float, float]]) -> torch.Tensor:\n",
    "        '''\n",
    "        Quantize the bias so that all values are integers between MIN_32B_SINT and MAX_32B_SINT.\n",
    "\n",
    "        Parameters:\n",
    "        bias (Tensor): The floating point values of the bias\n",
    "        n_w (float): The scale by which the weights of this layer were multiplied\n",
    "        n_initial_input (float): The scale by which the initial input to the neural network was multiplied\n",
    "        ns ([(float, float)]): A list of tuples, where each tuple represents the \"weight scale\" and \"output scale\" (in that order) for every preceding layer\n",
    "\n",
    "        Returns:\n",
    "        Tensor: The bias in quantized form, where every value is an integer between MIN_32B_SINT and MAX_32B_SINT.\n",
    "                The \"dtype\" will still be \"float\", but the values themselves should all be integers.\n",
    "        '''\n",
    "\n",
    "        # ADD YOUR CODE HERE\n",
    "        \n",
    "        return torch.clamp((bias).round(), min=MIN_32B_SINT, max=MAX_32B_SINT)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_quantized_with_bias = NetQuantizedWithBias(net_with_bias_with_quantized_weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Question 5.3:\n",
    "\n",
    "# What is your accuracy before and after quantizing CNN with the bias?\n",
    "# The accuracy change should ideally be negligible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = test(net_quantized_with_bias, testloader)\n",
    "print('Accuracy of the network on the test images after all the weights and the bias are quantized: {}%'.format(score))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5179d32cf6ec497baf3f8a3ef987cc77c5d2dc691fdde20a56316522f61a7323"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
